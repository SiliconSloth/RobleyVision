# Author: SiliconSloth 18/1/2018
import cv2
# PyCharm seems to need this to work properly.
try:
    from cv2 import cv2
except:
    pass
import numpy as np
import cPickle, os, random


# This script allows you to view the debug video and log files generated by Driver.py.
# It can be set to view specific files, or automatically view the latest debug video.
# It also reproduces the matching and flow calculation process used by Driver.py and visualises the results,
# to allow for easier debugging.  Modifying these processes in the viewer is a good way to test out new ideas
# without having to actually run the robot.
#
# Keyboard controls:
# a/d: Go forward/back one frame
# z/c: Go forward/back 10 frames
# v/n: Go forward/back 100 frames
# e:   Clear the output terminal
# x:   Switch between camera and target frames
# q:   Close the software


videoPath = "/home/someone/RobleyVision/Recordings/"  # Where video files will be saved to.

# Names of files to view, should form a matching number pair.  Uncomment code below to automatically choose latest video and log.
videoFile = "Debug1.avi"
logFile = "DebugLog1.pkl"

# Uncomment to automatically choose latest video and log.
# lastNo = 0
# for file in os.listdir(videoPath):
#     if file.startswith("Debug") and file.endswith(".avi"):
#         try:
#             lastNo = max(lastNo, int(file.replace("Debug", "").replace(".avi", "")))
#         except:
#             pass
# videoFile = "Debug"+str(lastNo)+".avi"
# logFile = "DebugLog"+str(lastNo)+".pkl"


# Function to find matching key points between two images.
def match(keypoints1, descriptors1, keypoints2, descriptors2):
    try:
        matches = bf.match(descriptors1, descriptors2)
        goodMatches = []
        for i,m in enumerate(matches):
            # Get the coordinates of the two key points in this match.
            point1, point2 = keypoints1[m.queryIdx].pt, keypoints2[m.trainIdx].pt
            # Realistically we know that key points will not have moved very far across the image.
            # If a matching is found between two points that are very far away from each other it is probably an
            # incorrect matching, and should be excluded from the results.
            if abs(point1[1] - point2[1]) < 100 and abs(point1[0] - point2[0]) < 100:
                goodMatches.append(m)

        return goodMatches
    except:
        # It is possible for bf.match() to throw an exception if it failed to find a match due to an insufficient number of key points.
        # If this happens, return an empty list of matches.
        return []


# Function to calculate the median optical flow between two images.
def calculateFlow(keypoints1, keypoints2, matches):
    # If the matching failed and returned an empty list the optical flow cannot be found.
    # If the matching contains less than 20 matches it is too poor to be reliable so don't use it.
    if not matches or len(matches) < 20:
        return None

    # Create a 2D array in which each row contains the x and y components of one optical flow vector.
    # Do this by subtracting the coordinates of the first key point of each match from the second key point's coordinates.
    flowVectors = np.array([(keypoints2[m.trainIdx].pt[0] - keypoints1[m.queryIdx].pt[0],
                             keypoints2[m.trainIdx].pt[1] - keypoints1[m.queryIdx].pt[1]) for m in matches])
    # Find the medians of all the x and y components.
    return np.median(flowVectors, 0)


# Load the video and log files.
capture = cv2.VideoCapture(videoPath+videoFile)
width, height = int(capture.get(3)/2), int(capture.get(4))  # Halve the width because the video has two frames side by side.
with open(videoPath+logFile, "rb") as file:
    debugLog = cPickle.load(file)

# Create the key point detector, descriptor extractor and matcher.
fast = cv2.FastFeatureDetector_create(threshold=16, nonmaxSuppression=True)
brief = cv2.xfeatures2d.BriefDescriptorExtractor_create(bytes=16, use_orientation=False)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

frameInd = 0    # The index of the frame currently being viewed.
useCamDisp = True   # Whether the camera or target frame is being viewed.
cv2.namedWindow("Viewer", cv2.WINDOW_NORMAL)
while True:
    # Set the capture to point to the frame at frameInd.
    capture.set(1, frameInd)

    # Get the frame from the debug video, and separate out the camera and target frames, which are stored side by side.
    frame = capture.read()[1]
    camera = frame[:, :frame.shape[1]/2, :]
    target = frame[:, frame.shape[1]/2:, :]

    # Detect key points and descriptors for the camera and target frames.
    camKeypoints = fast.detect(camera, None)
    camKeypoints, camDescriptors = brief.compute(camera, camKeypoints)

    # Only retain the best 2000 key points in the target frame, to match the behaviour of FeatureDetector.py.
    # Driver.py does not perform this filtering on the camera key points, so we do not do it to the camera frame here.
    maxFeatures = 2000
    targetKeypoints = fast.detect(target, None)
    targetKeypoints.sort(key=lambda x: x.response, reverse=True)
    targetKeypoints = targetKeypoints[:maxFeatures]
    targetKeypoints, targetDescriptors = brief.compute(target, targetKeypoints)

    # Do the matching and use it to find the median flow vector between the camera and target frames.
    matches = match(camKeypoints, camDescriptors, targetKeypoints, targetDescriptors)
    flow = calculateFlow(camKeypoints, targetKeypoints, matches)

    # The key points and matches can be drawn over either the camera or target frame.
    display = (camera if useCamDisp else target).copy()
    # Draw circles at all the key points of this frame.
    cv2.drawKeypoints(display, camKeypoints if useCamDisp else targetKeypoints, display)
    for m in matches:
        # Get the coordinates of the two key points in this match, converted to integers.
        point1 = tuple([int(x) for x in camKeypoints[m.queryIdx].pt])
        point2 = tuple([int(x) for x in targetKeypoints[m.trainIdx].pt])
        # Generate a random colour to draw the match with.
        colour = (random.randint(0,256), random.randint(0,256), random.randint(0,256))

        # Draw a dot on the camera key point, with a line to the target one.
        cv2.circle(display, point1, 1, colour, 1)
        cv2.line(display, point1, point2, colour)

    # Display the annotated frame and print the log entry for this frame and the calculated optical flow.
    cv2.imshow("Viewer", display)
    print(debugLog[frameInd])
    print(flow)

    # Wait for the user to press a key and perform the associated action.  we do this in a loop so that if the user
    # presses a key with no action, we can simply wait for them to press another one.
    key = -1
    while True:
        key = chr(cv2.waitKey(0) & 255)
        if key == "a":
            # Reduce the frame index by one, making sure not to go below 0.
            frameInd = max(frameInd-1, 0)
            break   # Don't wait for another key press.
        elif key == "d":
            # Increase the frame index by one, making sure not to exceed the last index in the video.
            frameInd = min(frameInd+1, len(debugLog)-1)
            break
        elif key == "z":
            # Reduce by 10.
            frameInd = max(frameInd-10, 0)
            break
        elif key == "c":
            # Increase by 10.
            frameInd = min(frameInd+10, len(debugLog)-1)
            break
        elif key == "v":
            # Reduce by 100.
            frameInd = max(frameInd-100, 0)
            break
        elif key == "n":
            # Increase by 100.
            frameInd = min(frameInd+100, len(debugLog)-1)
            break
        elif key == "e":
            # Print 100 empty lines to effectively clear the terminal. Wait for another key press as this does not require the frame to be redrawn.
            print("\n"*100)
        elif key == "x":
            # Switch between showing the camera and target frames.
            useCamDisp = not useCamDisp
            break
        elif key == "q":
            break   # Exit the software.
    if key == "q":
        break   # Exit the loop to terminate the script.
